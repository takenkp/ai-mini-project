# EU AI Act 요약

## 개요
EU AI Act는 유럽연합에서 제정한 인공지능 규제 프레임워크로, AI 시스템의 위험도에 따라 차등적인 규제를 적용하는 위험 기반 접근법을 채택하고 있습니다. 이 법안은 AI 시스템의 안전성, 투명성, 책임성을 보장하고 기본권을 보호하는 것을 목표로 합니다.

## 주요 위험 분류

### 1. 금지된 AI 사용 사례 (Prohibited AI Practices)
- 잠재의식적 조작 기술
- 취약 계층 착취
- 사회적 신용 평가 시스템
- 실시간 원격 생체인식 시스템 (법 집행 목적 외)

### 2. 고위험 AI 시스템 (High-Risk AI Systems)
- 중요 인프라 (교통, 물, 가스, 전기 등)
- 교육 및 직업 훈련
- 고용, 근로자 관리, 자영업 접근
- 필수 서비스 접근 (신용평가, 사회보장 등)
- 법 집행
- 이민, 망명, 국경 통제
- 사법 행정 및 민주적 프로세스

### 3. 제한된 위험 AI 시스템 (Limited Risk AI Systems)
- 챗봇과 같은 사람과 상호작용하는 AI 시스템
- 감정 인식 시스템
- 생체인식 분류 시스템
- 딥페이크 생성 시스템

### 4. 최소 위험 AI 시스템 (Minimal Risk AI Systems)
- 스팸 필터와 같은 기본적인 AI 시스템
- AI 기반 비디오 게임
- 추천 시스템 (특정 조건 충족 시)

## 주요 윤리적 요구사항

### 1. 편향성(Bias) 및 공정성
- AI 시스템은 차별적이지 않아야 함
- 학습 데이터의 다양성과 대표성 보장
- 정기적인 편향성 평가 및 모니터링 필요
- 편향된 결과를 식별하고 완화하는 메커니즘 구현

### 2. 프라이버시(Privacy) 및 데이터 보호
- GDPR 준수 의무
- 데이터 최소화 원칙 적용
- 개인정보 처리에 대한 명확한 동의 획득
- 데이터 보안 조치 구현
- 데이터 주체의 권리 보장 (접근, 삭제, 정정 등)

### 3. 설명가능성(Explainability) 및 투명성
- AI 시스템의 결정 과정에 대한 설명 제공
- 사용자에게 AI와 상호작용 중임을 알림
- 기술 문서 및 사용 지침 제공
- 고위험 AI 시스템의 경우 상세한 기술 문서 요구

### 4. 자동화 위험성(Automation Risk) 및 인간 감독
- 고위험 AI 시스템에 대한 인간의 감독 보장
- 자동화된 결정에 대한 인간의 개입 가능성 제공
- 시스템 오작동 시 안전 조치 구현
- 위험 관리 시스템 구축

## 규정 준수 요구사항

### 1. 위험 관리 시스템
- AI 시스템의 전체 수명 주기에 걸친 위험 식별 및 분석
- 위험 완화 조치 구현
- 정기적인 위험 평가 수행

### 2. 데이터 및 데이터 거버넌스
- 고품질 학습 데이터 사용
- 데이터 편향 방지 조치
- 데이터 보안 및 개인정보 보호

### 3. 기술 문서
- 시스템 설계 및 개발에 관한 상세 정보
- 위험 관리 조치에 관한 정보
- 검증 및 테스트 결과

### 4. 기록 보관
- AI 시스템의 활동에 대한 자동 로그 생성
- 시스템 기능 및 오작동 추적

### 5. 투명성 및 사용자 정보 제공
- 사용자에게 AI 시스템의 기능, 한계, 위험에 관한 정보 제공
- 인간과 상호작용하는 AI 시스템임을 명시

### 6. 인간 감독
- 인간 감독자의 역할 및 책임 정의
- 감독자에게 필요한 권한, 역량, 교육 제공

### 7. 정확성, 견고성, 사이버보안
- 시스템의 정확성 보장
- 외부 공격에 대한 복원력 확보
- 오작동 시 백업 및 복구 계획 구현

## 결론
EU AI Act는 AI 시스템의 위험도에 따라 차등적인 규제를 적용함으로써, 혁신을 저해하지 않으면서도 AI의 안전하고 윤리적인 사용을 보장하고자 합니다. 이 법안은 AI 개발자와 배포자에게 명확한 가이드라인을 제공하며, 사용자와 영향을 받는 개인의 권리를 보호하는 프레임워크를 제시합니다.